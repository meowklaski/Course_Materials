{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from scipy.signal import fftconvolve, convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def max_pool(x, pool_shape, stride, pooling_axes, backprop=False, dout=None):\n",
    "    \"\"\" Pool the values of an ndarray, by taking the max over a specified pooling\n",
    "        filter volume that rasters across the specified axes of x with a given stride.\n",
    "\n",
    "        A backprop flag can be toggled to, instead, perform back-propagation through the\n",
    "        maxpool layer (i.e. pass gradient values through of the array elements that\n",
    "        contributed to the forward pooling).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray\n",
    "            Input array to be pooled.\n",
    "        pool_shape : Iterable[int, ...]\n",
    "            Shape of pooling filter.\n",
    "        stride : int ( > 0)\n",
    "            Step size used while rastering the pooling filter across x.\n",
    "        pooling_axes : Union[int, Iterable[int, ...]]\n",
    "            The axes along which the values of x will be max-pooled.\n",
    "        backprop : bool, optional\n",
    "            Indicates whether or not max_pool performs back propagation\n",
    "            instead of pooling.\n",
    "        dout : Union[NoneType, numpy.ndarray]\n",
    "            \"Upstream\" array, whose values will be back propagated through\n",
    "             the max-pool layer. This must be specified if backprop is True.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        if backprop is False\n",
    "            out : numpy.ndarray\n",
    "                An array of the max-pooled values of x.\n",
    "\n",
    "        if backprop is True\n",
    "            dx : numpy.ndarray (shape=x.shape)\n",
    "                An array of values from dout back-propagated through the pooling layer.\n",
    "        \"\"\"\n",
    "\n",
    "    if type(pooling_axes) is int:\n",
    "        pooling_axes = (pooling_axes)\n",
    "    pooling_axes = tuple(pooling_axes)\n",
    "    \n",
    "    assert len(pooling_axes) == len(pool_shape)\n",
    "    pool_only_slice = tuple(slice(None, None) if i in pooling_axes else 0 for i in range(x.ndim))\n",
    "    outshape = get_outshape(x[pool_only_slice].shape, pool_shape, stride)\n",
    "\n",
    "    if backprop:\n",
    "        assert dout is not None, \"dout must be provided during backprop\"\n",
    "        mask_view = tuple(np.newaxis if i in pooling_axes else slice(None, None) for i in range(x.ndim))\n",
    "        dx = np.zeros_like(x, dtype=x.dtype)\n",
    "\n",
    "    else:\n",
    "        tmp_shape = list(x.shape)\n",
    "        for i, ax in enumerate(pooling_axes):\n",
    "            tmp_shape[ax] = outshape[i]\n",
    "        out = np.zeros(tmp_shape, dtype=x.dtype)\n",
    "\n",
    "    all_slices = [slice(None, None) for i in range(x.ndim)]\n",
    "\n",
    "    # iterate over positions to place the pooling filter\n",
    "    for i, pos in enumerate(product(*[stride*np.arange(i) for i in outshape])):\n",
    "\n",
    "        slices = all_slices[:]\n",
    "        # generate slices to make pooling filter views of x\n",
    "        for j, start in enumerate(pos):\n",
    "            slices[pooling_axes[j]] = slice(start, start + pool_shape[j])\n",
    "        slices = tuple(slices)\n",
    "\n",
    "        # generate slices of output array to update\n",
    "        inds = np.unravel_index(i, outshape)\n",
    "        loc = all_slices[:]\n",
    "        for cnt, ax in enumerate(pooling_axes):\n",
    "            loc[ax] = inds[cnt]\n",
    "\n",
    "        maxes = np.amax(x[slices], axis=pooling_axes)\n",
    "\n",
    "        if not backprop:\n",
    "            out[loc] = maxes\n",
    "        else:\n",
    "            dx[slices][np.where(x[slices] == maxes[mask_view])] = dout[loc].flat\n",
    "\n",
    "    if not backprop:\n",
    "        return out\n",
    "    else:\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_outshape(dat_shape, kernel_shape, stride):\n",
    "    \"\"\" Returns the shape of the ndarray resulting from the convolution, using specified stride,\n",
    "        of two ndarrays whose shapes are specified.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dat_shape : Iterable[int, ...]\n",
    "            Shape of array to be convolved over.\n",
    "        kernel_shape : Iterable[int, ...]\n",
    "            Shape of kernel used to perform convolution.\n",
    "        stride : int ( > 0)\n",
    "            Step size used while sliding the kernel during the convolution.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : numpy.ndarray([int, ...])\n",
    "            Shape of the array resulting from the convolution.\"\"\"\n",
    "    dat_shape = np.array(dat_shape)\n",
    "    kernel_shape = np.array(kernel_shape)\n",
    "\n",
    "    assert stride > 0\n",
    "    stride = int(round(stride))\n",
    "    assert len(dat_shape) == len(kernel_shape), \"kernel and data must have same number of dimensions\"\n",
    "\n",
    "    outshape = (dat_shape-kernel_shape)/stride+1.\n",
    "    for num in outshape:\n",
    "        assert num.is_integer(), num\n",
    "    outshape = np.round(outshape).astype(int)\n",
    "\n",
    "    return outshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_ndarray(x):\n",
    "    \"\"\" Reverse the positions of the entries of the input array along all of its axes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : numpy.ndarray\n",
    "            A view of x with all of its axes reversed. Since a view is returned, this operation is O(1).\n",
    "\n",
    "        Example\n",
    "        ------\n",
    "        x = array([[1, 2, 3],\n",
    "                   [6, 5, 6]])\n",
    "        flip_ndarray(x))\n",
    "        >> array([[6, 5, 4],\n",
    "                  [3, 2, 1]])\"\"\"\n",
    "    loc = tuple(slice(None, None, -1) for i in xrange(x.ndim))\n",
    "    return x[loc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def padder(dat, pad, skip_axes=[0]):\n",
    "    \"\"\" Returns an array padded with zeros with specified depth on both sides of each axis. A list of\n",
    "        axes can be specified, which will not receive any padding.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dat : numpy.ndarray\n",
    "            Array to be padded\n",
    "        pad : int ( >= 0)\n",
    "            Padding depth to be used on each end of a padding axis.\n",
    "        skip_axes : Union[int, Iterable[int, ...]]\n",
    "            The indices corresponding to axes that will not be padded.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : numpy.ndarray\n",
    "            Array padded with zeros.\"\"\"\n",
    "    assert pad >= 0 and type(pad) == int\n",
    "    if pad == 0:\n",
    "        return dat\n",
    "\n",
    "    if type(skip_axes) == int:\n",
    "        skip_axes = [skip_axes]\n",
    "    assert hasattr(skip_axes, '__iter__')\n",
    "    padding = [(pad, pad) for i in xrange(dat.ndim)]\n",
    "\n",
    "    for ax in skip_axes:\n",
    "        padding[ax] = (0, 0)\n",
    "\n",
    "    return np.pad(dat, padding, mode='constant').astype(dat.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_convd(dat, raster_kernel, stride, outshape=None):\n",
    "    \"\"\" Perform a dot-product convolution of a n-dim kernel with n-dim data\"\"\"\n",
    "    if outshape is None:\n",
    "        outshape = get_outshape(dat.shape, raster_kernel.shape, stride)\n",
    "    out = np.zeros(outshape, dtype=dat.dtype)\n",
    "    indices = range(dat.ndim)\n",
    "    # iterate over positions to place the kernel\n",
    "    for i,x in enumerate(product(*[stride*np.arange(i) for i in outshape])):\n",
    "        # generate slices to make pooling kernel views of x\n",
    "        slices = tuple(slice(start, start+raster_kernel.shape[j]) for j,start in enumerate(x))\n",
    "        loc = np.unravel_index(i, outshape)\n",
    "        out[loc] = np.einsum(dat[slices], indices, raster_kernel, indices)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = np.arange(2*3*4).reshape(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool_shape = (3,2)\n",
    "pool_axes  = (1,2)\n",
    "stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 9, 11]],\n",
       "\n",
       "       [[21, 23]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pool(dat, pool_shape, stride, pool_axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def back_prop_dw(data, dout, kernel, stride, pad):\n",
    "    dw = np.zeros_like(kernel, dtype=kernel.dtype)\n",
    "    for n, dat in enumerate(data):\n",
    "        dy = dout[n][np.newaxis, :, :]\n",
    "        if n == 0:  # initialize output and stride information\n",
    "            npad = np.array([0]+[pad for i in xrange(dat.ndim-1)])\n",
    "            outshape = (np.array(dat.shape)-np.array(kernel.shape)+2.*npad)/float(stride)+1.\n",
    "            outshape = np.round(outshape).astype(int)\n",
    "\n",
    "            if pad:\n",
    "                pad = [(0, 0)] + [(pad, pad) for i in xrange(dat.ndim-1)]\n",
    "\n",
    "        all_pos = list(product(*[stride*np.arange(i) for i in outshape]))\n",
    "        all_slices = [tuple(slice(start, start+kernel.shape[i]) for i,start in enumerate(x)) for x in all_pos]\n",
    "\n",
    "        if pad:\n",
    "            dat = np.pad(dat, pad, mode='constant').astype(dat.dtype)\n",
    "\n",
    "        for i,slices in enumerate(all_slices):\n",
    "            loc = np.unravel_index(i, outshape)\n",
    "            dw += dy[loc]*dat[slices]\n",
    "    return dw\n",
    "\n",
    "\n",
    "def back_prop_dx(data, dout, kernel, stride, pad):\n",
    "    for n, dat in enumerate(data):\n",
    "        dy = dout[n][np.newaxis, :, :]\n",
    "        out = np.zeros((dat.shape[0], dat.shape[1]+2*pad, dat.shape[2]+2*pad), dtype=data.dtype)\n",
    "        if n == 0:  # initialize output and stride information\n",
    "            npad = np.array([0]+[pad for i in xrange(dat.ndim-1)])\n",
    "            outshape = (np.array(dat.shape)-np.array(kernel.shape)+2.*npad)/float(stride)+1.\n",
    "            outshape = np.round(outshape).astype(int)\n",
    "\n",
    "            total_out = np.zeros(data.shape, dtype=dat.dtype)\n",
    "            all_pos = list(product(*[stride*np.arange(i) for i in outshape]))\n",
    "            all_slices = [tuple(slice(start, start+kernel.shape[i]) for i,start in enumerate(x)) for x in all_pos]\n",
    "\n",
    "        for i, slices in enumerate(all_slices):\n",
    "            loc = np.unravel_index(i, outshape)\n",
    "\n",
    "            out[slices] += dy[loc]*kernel\n",
    "\n",
    "        if pad:\n",
    "            out = out[:, pad:-pad, pad:-pad]\n",
    "\n",
    "        total_out[n] = out[:]\n",
    "    return total_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_layer_conv(data, kernel, stride, pad, flip_kernel=True, outshape=None, channels=True):\n",
    "    \"\"\" Perform a convolution on a collection of ndarrays of uniform shape with a kernel,\n",
    "        using a specified stride and padding.\n",
    "\n",
    "        The convolution\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Iterable[numpy.ndarray, ...]\n",
    "            Collection of arrays to be convolved over.\n",
    "        kernel : numpy.ndarray\n",
    "            Kernel used to perform convolution.\n",
    "        stride : int ( > 0)\n",
    "            Step size used while sliding the kernel during the convolution.\n",
    "        pad : int ( >= 0)\n",
    "            Specifies the number of zeroes added to every side of each input array.\n",
    "        flip_kernel : bool, optional\n",
    "            When True (default), reverse all of the axes of the kernel before performing convolutions.\n",
    "        outshape : Union[NoneType, Tuple[int, ...]], optional\n",
    "            Provide the known output shape of the convolution, allowing the function to bypass\n",
    "            sanity checks and some initial computations.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : numpy.ndarray, shape = (len(data), data[0].shape[0], data[0].shape[1], ...)\n",
    "            An array of the resulting convolutions. The first axis runs over the results of\n",
    "            the independent convolutions that were performed.\n",
    "        \"\"\"\n",
    "\n",
    "    if flip_kernel:\n",
    "        kernel = flip_ndarray(kernel)\n",
    "    for n, dat in enumerate(data):\n",
    "        if n == 0:  # initialize output and stride information\n",
    "            if np.max(dat.shape) >= 500:\n",
    "                conv = fftconvolve  # use fft method for large input arrays\n",
    "            else:\n",
    "                conv = convolve\n",
    "\n",
    "            if outshape is None:\n",
    "                npad = np.array([0]+[pad for i in xrange(dat.ndim-1)])\n",
    "                outshape = (np.array(dat.shape)-np.array(kernel.shape)+2.*npad)/float(stride)+1.\n",
    "                for num in outshape:\n",
    "                    assert (num).is_integer(), num\n",
    "                outshape = np.round(outshape).astype(int)\n",
    "\n",
    "            if pad:\n",
    "                if channels:\n",
    "                    pad = [(0, 0)] + [(pad, pad) for i in xrange(dat.ndim-1)]\n",
    "\n",
    "            total_out_shape = tuple([data.shape[0]]+[i for i in outshape])\n",
    "            total_out = np.zeros(total_out_shape, dtype=dat.dtype)\n",
    "\n",
    "            all_pos = zip(*product(*(stride*np.arange(i) for i in outshape)))\n",
    "\n",
    "        if pad:\n",
    "            dat = np.pad(dat, pad, mode='constant').astype(dat.dtype)\n",
    "\n",
    "        full_conv = conv(dat, kernel, mode='valid')\n",
    "        if stride == 1:\n",
    "            total_out[n] = full_conv\n",
    "        else:\n",
    "            out = np.zeros(outshape, dtype=full_conv.dtype)\n",
    "            out.flat = full_conv[all_pos]\n",
    "            total_out[n] = out\n",
    "    return total_out\n",
    "\n",
    "for n, kernel in enumerate(w):\n",
    "    out[:, n:n+1, :, :] = multi_layer_conv(x, kernel, conv_param['stride'], conv_param['pad'])\n",
    "    out[:, n:n+1, :, :] += b[n]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
